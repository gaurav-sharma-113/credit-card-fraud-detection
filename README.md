# Credit Card Fraud Detection

This project is to build a model for detecting fraudulent credit card transactions.

The dataset that we use is the credit card transaction dastaset. 

We do a preliminary Exploratory Data Analysis (EDA), and then try to spot duplicate transactions. These are identified as transactions which are:

- Reversed: a purchase is followed by reversal
- Multiple-swipe: a vendor accidently charges a customer's card multiple times within a short span of time

The methodology to do that is explained in the corresponding cells in the notebook. 
The goal is to identify this and observe the pattern, if any.

Then the next goal is to build a model that can determine if the transaction will be fraudulent or not. We are using different models (though basic ones) for modeling and analysis. The dataset faces class imbalance problem so we deal with this by 2 approaches, i.e. using techniques to oversample the underrepresented class and undersample the overrepresented class (discussed later). The models which are used are: 

- **Logistic Regression** : Logistic Regression is the most basic binary classification algorithm and hence, we must compare its performance with other algorithms.
- **Decision Trees** : It is a flowchart like structure for classification problems. A decision tree follows a set of if-else conditions to visualize the data and classify it according to the conditions. Hence, we attempt to use this algorithm to see if this structure is suited for out task.
- **Gaussian Naive Bayes** : Naive Bayes classifiers are a family of simple "probabilistic classifiers" based on applying Bayes' theorem with strong independence assumptions between the features. They are among the simplest Bayesian network models, with strongest assumption of independence between features which is unlikely in real data, yet the approach performs surprisingly well on data where this assumption does not hold. Hence, we try to make use of this approach in our problem. Also, due to the assumption of independence, it is faster to train.
- **Random Forest** : The fundamental concept of random forests is "wisdom of crowds". Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction. Uncorrelated models (trees) can produce ensemble predictions that are more accurate than any of the individual predictions. Hence, since we make use of decision trees, we also consider this approach for classifying our problem.
- **Quadratic discriminant analysis** : A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule. This is good for bringinig in non-linearity into the function and is more stable than Logistic Regression. The model fits a Gaussian density to each class.
- **Neural Network (MLP)** : The most basic neural network, single layer. This is our attempt to try to use neural network to this problem.
Deep Neural Network: While MLP is a single layer network, we try to go further deep in order to explore how much better performance we can achieve with Deep network. We train for 2 epochs to save time.

The metric we use for evaluating the performance of the algorithm would be area under the curve because accuracy can be misleading in such imbalanced datasets.

- **Area Under the curve (AUC)**: represents likelihood of model distinguishing observations from two classes.
- **Precision**: It is the number of true positives divided by all positive predictions. It is also called positive predictive value and is a measure of classifier's exactness. Low precision value indicates high number of false positives.

In order to deal with class imbalance problems, we have to make sure that we consider data from all classes equally. However, there can be problems that we might run into and this can lead to poor performances.

One of the major disadvantages of using **under-sampling** is that it can discard potentially useful information which can be useful in building classifiers. Also, it might be the case that the samples chosen in undersampling might not represent the population accurately and hence might fail on test dataset. Despite all this, it can train faster and give a quick glance into the prediction performance of the model/algorithms which can be used to build upon more complex algorithms.

On the other hand, **over-sampling** does not lead to information loss, and it can outperform under-sampling, which we see in the results. However, because the information is repeated, there is a chance of overfitting.
